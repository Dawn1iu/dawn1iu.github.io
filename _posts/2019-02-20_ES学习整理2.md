### shards

### Node

* Master-eligible node

一个节点的node.master设置为true（默认），这使得它有资格被选为主节点（超连接），它控制集群。

主节点负责轻量级的集群范围的操作，Eg创建或删除索引，跟踪哪些节点是集群的一部分，以及决定哪些分片分配给哪些节点。 群集健康对于拥有稳定的主节点很重要。任何主节点（默认情况下的所有节点）可以通过选举过程被选为成为主节点(master election process)。

```//todo ZenDiscovery```

```
GET _cat/nodes?v

ip             heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
10.171.165.128            4          88   0    0.01    0.02     0.07 -         -      client_1
10.171.165.122           13          94   1    0.00    0.01     0.05 m         -      master_2
10.171.165.125           52          97   4    0.07    0.08     0.25 d         -      data_2
10.171.165.124           43          96   6    0.14    0.08     0.07 d         -      data_1
10.171.165.127            3          84   1    0.00    0.01     0.05 -         -      client_0
10.171.165.123           51          98   5    0.00    0.02     0.07 d         -      data_0
10.171.165.120           15          95   1    0.25    0.08     0.07 m         -      master_0
10.171.165.121           15          95   1    0.00    0.02     0.05 m         *      master_1
10.171.165.126           61          96   5    0.32    0.11     0.07 d         -      data_3


GET _cat/nodes?v&h=ip,heap.percent
```

* Data node

node.data设置为true（默认）的节点。数据节点保存数据并执行数据相关操作，Eg: CRUD，搜索和聚合。

数据节点保存包含已编制索引的文档的分片。 数据节点处理与CRUD，搜索和聚合相关的数据相关操作。 这些操作是I / O，内存和CPU密集型。 如果监视这些资源并重新加载更多的数据节点，这是非常重要的。拥有独立数据节点的主要优点是主控和数据角色的分离。


* Ingest node

node.ingest设置为true（默认）的节点。 获取节点能够将 ingest pipeline 应用于文档，以便在索引之前变换和丰富文档。 使用沉重的请求负载，使用专门的请求节点并将主节点和数据节点标记为node.ingest：false是有意义的。

* 协调 node

 搜索请求或批量索引请求的可能涉及保存在不同数据节点上的数据。 Eg，搜索请求在由接收客户端请求的节点（协调节点）协调的两个阶段中执行。在分散阶段，协调节点将请求转发到保存数据的数据节点。 每个数据节点在本地执行请求，并将其结果返回给协调节点。 在收集阶段，协调节点将每个数据节点的结果减少为单个全局结果集。每个节点都是隐式协调节点。 这意味着将所有三个node.master，node.data和node.ingest设置为false的节点将仅作为协调节点，不能禁用。 因此，这样一个节点需要有足够的内存和CPU才能处理收集阶段。


#### tips

##### 增加字段
```
PUT my_index/_mapping/my_type
{
  "properties": {
    "new_column": { 
      "type":     "integer"
    }
  }
}

POST my_index/_update_by_query
{
  "script": {
    "lang": "painless",
    "inline": "if ctx._source.a  == null ctx._source.new_column= '02' else ctx._source.new_column= '03' "
  }
}


```
##### function score
function_score 允许你修改一个查询检索文档的分数。举例来讲，当得分函数计算代价高昂并且足以在经过滤的文档集合上计算得分，这种查询是有用的。
使用 function_score ，用户需要定义一个查询和一个或多个功能，即计算用于由查询返回的每个文档的新得分。


function_score 查询提供的几种函数分数的类型
1. script_score
2. weight
3. random_score
4. field_value_factor
5. decay functions: gauss, linear, exp

```
GET /_search
{
    "query": {
        "function_score": {
            "query": { "match_all": {} },
            "boost": "5",
            "random_score": {},//注释1
            "boost_mode":"multiply"
        }
    }
}

GET /_search
{
    "query": {
        "function_score": {
          "query": { "match_all": {} },
          "boost": "5", //注释1
          "functions": [
              {
                  "filter": { "match": { "test": "bar" } },
                  "random_score": {}, //注释2
                  "weight": 23
              },
              {
                  "filter": { "match": { "test": "cat" } },
                  "weight": 42
              }
          ],
          "max_boost": 42,
          "score_mode": "max",
          "boost_mode": "multiply",
          "min_score" : 42
        }
    }
}


GET logstash-2019.02.09/_search
{
  "size":0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "tag": {
      "terms": {
        "field": "TAG"
        , "size": 100
      }
    }
  }
}


GET category_live_relation_aliased/category_live_relation_aliased/_search
{
  "from" : 0,
  "size" : 12,
  "query" : {
    "function_score" : {
      "query" : {
        "bool" : {
          "filter" : [
            {
              "range" : {
                "endTime" : {
                  "from" : 1550803390112,
                  "to" : null,
                  "include_lower" : true,
                  "include_upper" : true,
                  "boost" : 1.0
                }
              }
            },
            {
              "exists" : {
                "field" : "liveName",
                "boost" : 1.0
              }
            },
            {
              "exists" : {
                "field" : "livePic",
                "boost" : 1.0
              }
            },
            {
              "exists" : {
                "field" : "lector",
                "boost" : 1.0
              }
            }
          ],
          "disable_coord" : false,
          "adjust_pure_negative" : true,
          "boost" : 1.0
        }
      },
      "functions" : [
        {
          "filter" : {
            "match_all" : {
              "boost" : 1.0
            }
          },
          "script_score" : {
            "script" : {
              "source" : " Long startTime = doc['startTime'].value; Long endTime = doc['endTime'].value; double gmtCreate = doc['gmtCreate'].value / 1000; double startTimed = doc['startTimeSortScore'].value; Long now = Long.valueOf(1550803390112L); Long categoryId = doc['categoryId'].value; double score = 1/startTimed; double homeScore = 0; double gmtCreateScore = 1/gmtCreate * 1000; if (Long.valueOf(-2L).compareTo(categoryId) == 0){     homeScore = score * 5000000 }  if (now.compareTo(startTime) > 0 && now.compareTo(endTime) < 0){     return score * 50000000 + homeScore + gmtCreateScore; }else if (Long.valueOf(-2L).compareTo(categoryId) == 0){     return homeScore + gmtCreateScore; }else {     return score * 500000 + gmtCreateScore; }",
              "lang" : "painless"
            }
          }
        }
      ],
      "score_mode" : "multiply",
      "max_boost" : 3.4028235E38,
      "boost" : 1.0
    }
  },
  "version" : true
}
```


### transpor tclient

#### 流程

客户端请求的流程：

先是实例化：
1. PreBuiltTransportClient(Settings, plugins, hostFailureListenter)实例
化
2. super实例化TransportClient
3. TransportClient执行buildTemplate方法
4. buildTemplate方法中实例化TransportClientNodesService类的对象nodesService

```
//这里应该有代码

```

然后是请求部分：
1. 请求从AbstractClient的不同请求方法中进入（如bulk，clearScroll，delete，explain，fieldCaps，get，index，multiGet，mutiSearch，multiTermVectors，search，searchScroll，termVectors，update）
2. 执行AbstractClient的execute(action, Request,listener)
3. 执行TransportClient的doExecute方法，执行TransportClient中proxy的execute
4. 执行TransportProxyClient的execute方法
5. 执行TransportClientNodesService实例nodesService的execute方法
6. 调用NodeListenerCallback回调方法doWithNode
7. 执行TransportActionNodeProxy的execute方法
8. 执行TransportService的sendRequest方法
9. TransportService调用sendRequest后的回调依次回传
TransportActionNodeProxy NodeListenerCallback TransportClientNodesService

整个客户端模块的简要流程如下：

client 提供了客户端的操作接口，比如count()
代理端TransportClientNodesService的execute()随机一个节点出来
代理端TransportClientNodesService通过transportService发送请求

#### failover

TransportClientNodesService的实例化首先注入了集群名称，线程池，最小兼容版本，客户端传输采样时间间隔，ping超时时间。然后配置了节点采样模型NodeSampler。NodeSampler接口很简单，只有一个sample()方法，它的实现类有2个SniffNodesSampler和SimpleNodeSampler，我们在初始化里已经看到了，如果"sniff"配置项是true的话使用SniffNodesSampler类。

两个实现类如下

* 嗅探同一集群中的所有节点（SniffNodesSampler，client会主动发现集群里的其他节点，即使节点不在配置文件中，会创建fully connect）

* 或者是只关注配置文件配置的节点（SimpleNodeSampler，ping listedNodes（也就是配置中设置的节点）中的所有node，区别在于这里创建的都是light connect）

简单的说，SimpleNodeSampler会限制当前可用client一定是在配置中设置的节点中的，这样的意图是让集群中的某些节点专门用来负责接收用户请求，而SniffNodesSampler会使用所有发现的节点，让其参与负载，即使这个节点不在配置中。

#### 负载均衡

Client的负载均衡是通过TransportClientNodesService类实现的。TransportClientNodesService实例维护一组DiscoveryNode引用，每次客户端请求的时候，会根据负载均衡算法选中一个节点（DiscoveryNode），发送请求。常用的负载算法有Random，Round robin，Hash，StaticWeighted等。ES的客户端负载使用了Round robin算法。

![1](https://upload-images.jianshu.io/upload_images/3034806-94586beaef06c49b.png)


### 搜索 (query&fetch)

#### query
在初始化查询阶段（query phase），查询被向索引中的每个分片副本（原本或副本）广播。每个分片在本地执行搜索并且建立了匹配document的优先队列（priority queue）。
```
一个优先队列（priority queue is）只是一个存有前n个（top-n）匹配document的有序列表。这个优先队列的大小由分页参数from和size决定。例如，下面这个例子中的搜索请求要求优先队列要能够容纳100个document
```
![](https://es.xiaoleilu.com/images/elas_0901.png)
查询阶段包含以下三步：

1. 客户端发送一个search（搜索）请求给Node 3,Node 3创建了一个长度为from+size的空优先级队列。
2. Node 3 转发这个搜索请求到索引中每个分片的原本或副本。每个分片在本地执行这个查询并且结果将结果到一个大小为from+size的有序本地优先队列里去。 
3. 每个分片返回document的ID和它优先队列里的所有document的排序值给协调节点Node 3。Node3 把这些值合并到自己的优先队列里产生全局排序结果。

当一个搜索请求被发送到一个节点Node，这个节点就变成了协调节点。这个节点的工作是向所有相关的分片广播搜索请求并且把它们的响应整合成一个全局的有序结果集。这个结果集会被返回给客户端。

第一步是向索引里的每个节点的分片副本广播请求。就像document的GET请求一样，搜索请求可以被每个分片的原本或任意副本处理。这就是更多的副本（当结合更多的硬件时）如何提高搜索的吞吐量的方法。对于后续请求，协调节点会轮询所有的分片副本以分摊负载。

每一个分片在本地执行查询和建立一个长度为from+size的有序优先队列——这个长度意味着它自己的结果数量就足够满足全局的请求要求。分片返回一个轻量级的结果列表给协调节点。只包含documentID值和排序需要用到的值，例如_score。

协调节点将这些分片级的结果合并到自己的有序优先队列里。这个就代表了最终的全局有序结果集。到这里，查询阶段结束。


#### fetch
查询阶段辨别出那些满足搜索请求的document，但我们仍然需要取回那些document本身。这就是取回阶段的工作，如图分布式搜索的取回阶段所示。

![](https://es.xiaoleilu.com/images/elas_0902.png)

1. 协调节点辨别出哪个document需要取回，并且向相关分片发出GET请求。
2. 每个分片加载document并且根据需要丰富（enrich）它们，然后再将document返回协调节点。
3. 一旦所有的document都被取回，协调节点会将结果返回给客户端。

协调节点先决定哪些document是实际（actually）需要取回的。例如，我们指定查询{ "from": 90, "size": 10 }，那么前90条将会被丢弃，只有之后的10条会需要取回。这些document可能来自与原始查询请求相关的某个、某些或者全部分片。

协调节点为每个持有相关document的分片建立多点get请求然后发送请求到处理查询阶段的分片副本。

分片加载document主体——_source field。如果需要，还会根据元数据丰富结果和高亮搜索片断。一旦协调节点收到所有结果，会将它们汇集到单一的回答响应里，这个响应将会返回给客户端。


#### 深分页
每个分片必须构造一个长度为from+size的优先队列吧，所有这些都要传回协调节点。这意味着协调节点要通过对分片数量 * (from + size)个document进行排序来找到正确的size个document。
根据document的数量，分片的数量以及所使用的硬件，对10,000到50,000条结果（1,000到5,000页）深分页是可行的。但是对于足够大的from值，排序过程将会变得非常繁重，会使用巨大量的CPU，内存和带宽。因此，强烈不建议使用深分页。


#### seach after
```
GET ljqtest/ljqtest/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "id": {
        "order": "desc"
      }
    }
  ],
  "search_after":["3"]
}
```

#### scroll

1. client端向coordinate node发起类似 /{index}/_search?scroll=1m的请求

2. coordinate node会根据参数初始化一个QueryThenFetch请求或者QueryAndFetch请求

3. client往后会向coordinate node发起类似 _search/scroll 请求，在这个请求里会带上上次查询返回的scroll_id参数，循环这个阶段知道无结果返回
4. client端会发起一个DELETE 操作向服务器请求查询已结束，清楚掉相关缓存




##### service调用链

```
RestSearchAction

RestSearchScrollAction

org/elasticsearch/action/ActionModule.java


SearchQueryThenFetchAsyncAction


FetchSearchPhase

```

![1](https://upload-images.jianshu.io/upload_images/14137218-7125b490fe34e206.png)